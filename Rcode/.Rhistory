#Carpet 函数插值
data_bag = Bag_inter(data)
col_names_for_test = get_Col_names_For_test(data_bag)
data_bag = Combine_All_features(data_bag)
data_bag = central_scale(data_bag)
source("test_functions.R",encoding = "utf-8")
col_names_for_test
data = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_train_complete.csv')
#Carpet 函数插值
data_bag = Bag_inter(data)
col_names_for_test = get_Col_names_For_test(data_bag)
data_bag = Combine_All_features(data_bag)
data_bag = central_scale(data_bag)
dim(data_bag)
test_set = getTestdata(col_names_for_test)
model_SVM_1 = svm(happiness ~., data = data_bag,type = type_reg2,kernel ="radial",gamma = 0.001,cost = 10)
type_reg = "eps-regression"
type_reg2 = "nu-regression"
model_SVM_1 = svm(happiness ~., data = data_bag,type = type_reg2,kernel ="radial",gamma = 0.001,cost = 10)
test_set = scale(test_set,center = T,scale = T)
SVM_test_result_1 = predict(model_SVM_1,test_set)
dim(test_set)
dim(data_bag)
data = delete_features_for_linear(data)
data_bag = delete_features_for_linear(data_bag)
test_set = subset(test_set,select = -c(survey_type,province,nationality,edu,income,
political,floor_area,health_problem,hukou,
hukou_loc,leisure_12,socialize,learn,socia_outing,
work_exper,family_income,son,f_political,f_work_14,
m_birth,m_political,inc_exp,invest,inc_income,trust_familar,
property_own,property_other,media_old,media_new,insurance,effort,f_birth,
religion_freq,house,marital))
model_SVM_1 = svm(happiness ~., data = data_bag,type = type_reg2,kernel ="radial",gamma = 0.001,cost = 10)
SVM_test_result_1 = predict(model_SVM_1,test_set)
colnames(data_bag)
rm(list=ls())
source("DataProcessFunctions.R",encoding = "utf-8")
source("TestSetProcess.R",encoding = "utf-8")
source("writeResult.R",encoding = "utf-8")
source("test_functions.R",encoding = "utf-8")
library("FactoMineR")
library("factoextra")
library(e1071)
library(arules)
library(glmnet)
library("neuralnet")
library(nnet)
library(rpart)
library(neuralnet)
library(rpart)
library(adabag)
library(ipred)
library(randomForest)
require(Hmisc)
require(caret)
data = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_train_complete.csv')
#幸福度插值
data_happiness_interpol = Happiness_inter(data)
#Carpet 函数插值
data_bag = Bag_inter(data)
describe(data_bag)
test_set = getTestdata(col_names_for_test)
col_names_for_test = get_Col_names_For_test(data_bag)
data_bag = Combine_All_features(data_bag)
data_bag = central_scale(data_bag)
test_set = getTestdata(col_names_for_test)
require(caret)
source("test_functions.R",encoding = "utf-8")
dataset = read.csv("D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_test_complete.csv")
rm(list=ls())
require(caret)
source("test_functions.R",encoding = "utf-8")
data = read.csv("D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_test_complete.csv")
for(i in 1:nrow(data)){
for (j in 1:ncol(data)){
if(data[i,j] < 0 || is.na(data[i,j])){
data[i,j] = NA
}
}
}
for(i in 1:nrow(data)){
for (j in 1:ncol(data)){
if(data[i,j] < 0 | is.na(data[i,j])){
data[i,j] = NA
}
}
}
data = read.csv("D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_test_complete.csv")
for(i in 1:nrow(data)){
for (j in 1:ncol(data)){
print(colnames(data)[j])
if(data[i,j] < 0 | is.na(data[i,j])){
data[i,j] = NA
}
}
}
rm(list=ls())
require(caret)
source("test_functions.R",encoding = "utf-8")
data = read.csv("D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_test_complete.csv")
rm(list=ls())
source("DataProcessFunctions.R",encoding = "utf-8")
source("TestSetProcess.R",encoding = "utf-8")
source("writeResult.R",encoding = "utf-8")
source("test_functions.R",encoding = "utf-8")
library("FactoMineR")
library("factoextra")
library(e1071)
library(arules)
library(nnet)
library(rpart)
library(neuralnet)
library(rpart)
library(adabag)
library(ipred)
library(randomForest)
require(Hmisc)
require(caret)
data = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_train_complete.csv')
#Carpet 函数插值
data_bag = Bag_inter(data)
col_names_for_test = get_Col_names_For_test(data_bag)
data_bag = Combine_All_features(data_bag)
data_bag = central_scale(data_bag)
test_set = getTestdata(col_names_for_test)
test_set = getTestdata(col_names_for_test)
require(caret)
source("test_functions.R",encoding = "utf-8")
rm(list=ls())
source("test_functions.R",encoding = "utf-8")
require(caret)
data = read.csv("D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_test_complete.csv")
data = Test_Process_col(data)
source("TestSetProcess.R",encoding = "utf-8")
data = read.csv("D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_test_complete.csv")
data = Test_Process_col(data)
for(i in 1:nrow(data)){
for (j in 1:ncol(data)){
print(colnames(data)[j])
if(data[i,j] < 0 | is.na(data[i,j])){
data[i,j] = NA
}
}
}
data = read.csv("D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_test_complete.csv")
data = Test_Process_col(data)
for(i in 1:nrow(data)){
for (j in 1:ncol(data)){
if(data[i,j] < 0 | is.na(data[i,j])){
data[i,j] = NA
}
}
}
tem_data = preProcess(data,method = "bagImpute")
data_tem = predict(tem_data,data)
data_bag_inter = data.frame(data_tem)
colnames(data_bag_inter)
data_bag_inter = Test_Process_col(data_bag_inter)
data_bag_inter = Test_Process_invest(data_bag_inter)
rm(list=ls())
source("DataProcessFunctions.R",encoding = "utf-8")
source("TestSetProcess.R",encoding = "utf-8")
source("writeResult.R",encoding = "utf-8")
source("test_functions.R",encoding = "utf-8")
library("FactoMineR")
library("factoextra")
library(e1071)
library(arules)
library(glmnet)
library("neuralnet")
library(nnet)
library(rpart)
library(neuralnet)
library(rpart)
library(adabag)
library(ipred)
library(randomForest)
require(Hmisc)
require(caret)
data = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_train_complete.csv')
#Carpet 函数插值
data_bag = Bag_inter(data)
col_names_for_test = get_Col_names_For_test(data_bag)
data_bag = Combine_All_features(data_bag)
data_bag = central_scale(data_bag)
test_set = getTestdata(col_names_for_test)
describe(test_set)
model_SVM_1 = svm(happiness ~., data = data_bag,type = type_reg2,kernel ="radial",gamma = 0.001,cost = 10)
type_reg = "eps-regression"
type_reg2 = "nu-regression"
model_SVM_1 = svm(happiness ~., data = data_bag,type = type_reg2,kernel ="radial",gamma = 0.001,cost = 10)
test_set = scale(test_set,center = T,scale = T)
dim(test_set)
dim(data_bag)
SVM_test_result_1 = predict(model_SVM_1,test_set)
writeResult(SVM_test_result_1)
new_result = read.csv("D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_submit.csv")
class(new_result[2,2])
new_result[2,2]
rm(list=ls())
source("DataProcessFunctions.R",encoding = "utf-8")
source("TestSetProcess.R",encoding = "utf-8")
source("writeResult.R",encoding = "utf-8")
source("test_functions.R",encoding = "utf-8")
library("FactoMineR")
library("factoextra")
library(e1071)
library(arules)
library(glmnet)
library("neuralnet")
library(nnet)
library(rpart)
library(neuralnet)
library(rpart)
library(adabag)
library(ipred)
library(randomForest)
require(Hmisc)
require(caret)
data = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_train_complete.csv')
#Carpet 函数插值
data_bag = Bag_inter(data)
#Carpet 函数插值
ptm = proc.time()
data_bag = Bag_inter(data)
# describe(data_bag)
proc.time() - ptm
# describe(data_bag)
print("The time cost is: "+proc.time() - ptm)
# describe(data_bag)
print(paste("The time cost is: ",proc.time() - ptm))
require(parallel)
require(doParallel)
install
install.packages("parallel")
install.packages("parallel")
require(doParallel)
rm(list=ls())
source("DataProcessFunctions.R",encoding = "utf-8")
source("TestSetProcess.R",encoding = "utf-8")
source("writeResult.R",encoding = "utf-8")
source("test_functions.R",encoding = "utf-8")
require(parallel)
require(doParallel)
library("FactoMineR")
library("factoextra")
library(nnet)
library(e1071)
library(arules)
library(glmnet)
library("neuralnet")
library(nnet)
library(neuralnet)
library(nnet)
library(rpart)
library(neuralnet)
library(rpart)
library(adabag)
library(ipred)
library(randomForest)
require(Hmisc)
require(caret)
data = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_train_complete.csv')
n_Cores <- detectCores()##检测你的电脑的CPU核数
cluster_Set <- makeCluster(n_Cores)##进行集群
registerDoParallel(cluster_Set)
data = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_train_complete.csv')
# data_id = data.frame(data[,"id"])
#幸福度插值
data_happiness_interpol = Happiness_inter(data)
data_bag = Bag_inter(data)
#========================================================================================
data_bag = Combine_All_features(data_bag)
data_bag = central_scale(data_bag)
#=======================函数测试方法=============================================
#SVM 函数测试
type_reg = "eps-regression"
type_reg2 = "nu-regression"
tuned <- tune.svm(happiness ~ .,type = type_reg2,kernel ="radial",data = data_bag,gamma = 10^(-6:-1),cost = 10^(1:2))
summary(tuned)
tuned <- tune.svm(happiness ~ .,type = type_reg2,kernel ="radial",data = data_bag,gamma = 10^(-6:-1),cost = 10^(1:2))
summary(tuned)
rm(list=ls())
source("DataProcessFunctions.R",encoding = "utf-8")
source("TestSetProcess.R",encoding = "utf-8")
source("writeResult.R",encoding = "utf-8")
source("test_functions.R",encoding = "utf-8")
require(parallel)
require(doParallel)
library("FactoMineR")
library("factoextra")
library(e1071)
library(arules)
library(glmnet)
library(neuralnet)
library(nnet)
library(rpart)
library(neuralnet)
library(rpart)
library(adabag)
library(ipred)
library(randomForest)
require(Hmisc)
require(caret)
#=======================================将train——data 与test结合在一起进行处理，然后进行分离================
traindata = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_train_complete.csv')
testdata = read.csv("D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_test_complete.csv")
traindata = Outlier_delete(traindata)
traindata_id = traindata[,"id"]
dim(traindata)
complete_data = data.frame(rbind(traindata,testdata))
traindata_happiness = traindata[,"happiness"]
traindata = subset(traindata,select = -c(happiness))
complete_data = data.frame(rbind(traindata,testdata))
dim(compelte_data)
complete_data = data.frame(rbind(traindata,testdata))
dim(compelte_data)
dim(complete_data)
10956-7988
#testdata 从 7969 开始 到 10956 结束
complete_data = Bag_inter(complete_data)
#testdata 从 7969 开始 到 10956 结束
complete_data = Bag_inter(complete_data)
source("DataProcessFunctions.R",encoding = "utf-8")
#testdata 从 7969 开始 到 10956 结束
complete_data = Bag_inter(complete_data)
dim(complete_data)
complete_data = Combine_All_features(complete_data)
dim(complete_data)
rm(list=ls())
source("DataProcessFunctions.R",encoding = "utf-8")
source("TestSetProcess.R",encoding = "utf-8")
source("writeResult.R",encoding = "utf-8")
source("test_functions.R",encoding = "utf-8")
require(parallel)
require(doParallel)
library("FactoMineR")
library("factoextra")
library(e1071)
library(arules)
library(glmnet)
library(neuralnet)
library(nnet)
library(rpart)
library(neuralnet)
library(rpart)
library(adabag)
library(ipred)
library(randomForest)
require(Hmisc)
require(caret)
n_Cores <- detectCores()##检测你的电脑的CPU核数
cluster_Set <- makeCluster(n_Cores)##进行集群
registerDoParallel(cluster_Set)
#=======================================将train——data 与test结合在一起进行处理，然后进行分离================
traindata = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_train_complete.csv')
testdata = read.csv("D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_test_complete.csv")
traindata = Outlier_delete(traindata)
traindata_id = traindata[,"id"]
traindata_happiness = traindata[,"happiness"]
traindata = subset(traindata,select = -c(happiness))
complete_data = data.frame(rbind(traindata,testdata))
#testdata 从 7969 开始 到 10956 结束
complete_data = Bag_inter(complete_data)
dim(complete_data)
Process_data  = preProcess(complete_data,method=c("scale","center","pca"))
complete_data = predict(Process_data,complete_data)
dim(complete_data)
#================================将train_data与test_data进行分裂============================
train_data = complete_data[1:7988,]
test_data = complete_data[7989:10956,]
dim(train_data)
dim(test_data)
cor_society = cor(train_data)
corrplot(cor_society,method="color",tl.pos = 'n')
require(corrplot)
corrplot(cor_society,method="color",tl.pos = 'n')
corrplot(cor_society,method="number",tl.pos = 'n')
type_reg = "eps-regression"
type_reg2 = "nu-regression"
model_SVM = svm(happiness ~., data = train_data,type = type_reg2,kernel ="radial",gamma = 0.001,cost = 10)
train_data = data.frame(cbind(traindata_happiness,train_data))
model_SVM = svm(happiness ~., data = train_data,type = type_reg2,kernel ="radial",gamma = 0.001,cost = 10)
colnames(train_data)
colnames(train_data)[1] = "happiness"
colnames(train_data)
type_reg = "eps-regression"
type_reg2 = "nu-regression"
model_SVM = svm(happiness ~., data = train_data,type = type_reg2,kernel ="radial",gamma = 0.001,cost = 10)
SVM_test_result_1 = predict(model_SVM,test_data)
writeResult(SVM_test_result_1)
new_result = read.csv("D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_submit.csv")
class(new_result[2,2])
new_result[2,2]
tuned <- tune.svm(happiness ~ .,type = type_reg2,kernel ="radial",data = train_data,gamma = 10^(-6:-1),cost = 10^(1:2))
summary(tuned)
dim(train_data)
dim(test_data)
model_SVM = svm(happiness ~., data = train_data,type = type_reg2,kernel ="radial",gamma = 0.001,cost = 10)
source("DataProcessFunctions.R",encoding = "utf-8")
source("TestSetProcess.R",encoding = "utf-8")
source("writeResult.R",encoding = "utf-8")
source("test_functions.R",encoding = "utf-8")
require(parallel)
require(doParallel)
library(e1071)
require(corrplot)
library(rpart)
library(adabag)
library(ipred)
library(randomForest)
require(Hmisc)
require(caret)
require(gputools)
n_Cores <- detectCores()##检测你的电脑的CPU核数
model_SVM = svm(happiness ~., data = train_data,type = type_reg2,kernel ="radial",gamma = 0.001,cost = 10)
SVM_test_result_1 = predict(model_SVM,test_data)
writeResult(SVM_test_result_1)
new_result = read.csv("D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_submit.csv")
class(new_result[2,2])
new_result[2,2]
View(tuned)
cluster_Set <- makeCluster(n_Cores)##进行集群
registerDoParallel(cluster_Set)
#=======================================将train_data与test结合在一起进行处理，然后进行分离================
traindata = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_train_complete.csv')
testdata = read.csv("D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_test_complete.csv")
traindata = Outlier_delete(traindata)
traindata_id = traindata[,"id"]
traindata_happiness = traindata[,"happiness"]
traindata = subset(traindata,select = -c(happiness))
complete_data = data.frame(rbind(traindata,testdata))
#testdata 从 7969 开始 到 10956 结束
complete_data = Bag_inter(complete_data)
#=============================使用 prepossess 函数进行降维=================================
Process_data_pca  = preProcess(complete_data,method=c("scale","center","pca"))
complete_data_pca = predict(Process_data_pca,complete_data)
#================================将train_data与test_data进行分裂============================
train_data = complete_data_pca[1:7988,]
train_data = data.frame(cbind(traindata_happiness,train_data))
colnames(train_data)[1] = "happiness"
colnames(train_data)
test_data = complete_data_pca[7989:10956,]
dim(train_data)
dim(test_data)
type_reg = "eps-regression"
type_reg2 = "nu-regression"
model_SVM = svm(happiness ~., data = train_data,type = type_reg2,kernel ="radial",gamma = 0.001,cost = 10)
SVM_test_result_1 = predict(model_SVM,test_data)
writeResult(SVM_test_result_1)
new_result = read.csv("D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_submit.csv")
class(new_result[2,2])
new_result[2,2]
install.packages("pander")
head(iris)
#构建train_data 与 test_data 以及train_data.abbr test_data.abbr
data_info = matrix(ncol = 4,nrow = 4)
data_info = data.frame(data_info)
colnames(data_info) = c("Name","Data","Feature","Missing Value")
data_info[,"Name"] = c("train.comp","test.comp","train.abbr","test.abbr")
data_info[,"Data"] = c(8000,8000,8000,8000)
#============构建train_data 与 test_data 以及train_data.abbr test_data.abbr==============
train.comp = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_train_complete.csv')
train.abbr = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_train_abbr.csv')
test.comp = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_test_complete.csv')
train.abbr = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_test_abbr.csv')
#============构建train_data 与 test_data 以及train_data.abbr test_data.abbr==============
train.comp = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_train_complete.csv')
train.abbr = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_train_abbr.csv')
test.comp = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_test_complete.csv')
test.abbr = read.csv('D:/Study/Jean Monnet/Data Mining/Project/Data/happiness_test_abbr.csv')
dim(train.comp)
dim(train.abbr)
dim(test.comp)
dim(test.abbr)
sum(is.na(train.comp))
sum(is.na(train.abbr))
sum(is.na(test.comp))
sum(is.na(test.abbr))
data_info[,"Missing Value"] = c(56903,21331,20197,7558)
data_info[,"Data"] = c(8000,8000,8000,8000)
data_info[,"feature"] = c(140,139,42,41)
data_info[,"Missing Value"] = c(56903,21331,20197,7558)
data_info
data_info[,"feature"] = c(140,139,42,41)
data_info[,"Feature"] = c(140,139,42,41)
data_info[,"Missing Value"] = c(56903,21331,20197,7558)
data_info
data_info = matrix(ncol = 4,nrow = 4)
data_info = data.frame(data_info)
colnames(data_info) = c("Name","Data","Feature","Missing Value")
data_info[,"Name"] = c("train.comp","test.comp","train.abbr","test.abbr")
data_info[,"Data"] = c(8000,8000,8000,8000)
data_info[,"Feature"] = c(140,139,42,41)
data_info[,"Missing Value"] = c(56903,21331,20197,7558)
data_info
data_info = matrix(ncol = 4,nrow = 4)
data_info = data.frame(data_info)
colnames(data_info) = c("Name","Data","Feature","NA")
data_info[,"Name"] = c("train.comp","test.comp","train.abbr","test.abbr")
data_info[,"Data"] = c(8000,8000,8000,8000)
data_info[,"Feature"] = c(140,139,42,41)
data_info[,"NA"] = c(56903,21331,20197,7558)
data_info
head(data_info)
c(12,'wa',23)
c('\')
c
q
as.array()
source("DataProcessFunctions.R",encoding = "utf-8")
outlier_train.comp = Outlier_num(train.comp)
